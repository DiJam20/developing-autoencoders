{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import random_noise\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from autoencoder import Autoencoder\n",
    "from solver import train_vali_all_epochs, dev_train_vali_all_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/david/sparsify_models/AE/MNIST/2024-11-08_10-05-23/\n"
     ]
    }
   ],
   "source": [
    "run_id = datetime.today().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "save_path = os.getenv(\"HOME\") + '/sparsify_models/AE/MNIST/' +run_id +'/'\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MNIST data to numpy arrays\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data = Variable(data).to('cuda')\n",
    "    input = data.view(data.size(0), -1).to('cuda')\n",
    "    train_images.append(input.cpu().numpy())\n",
    "    train_labels.append(target.cpu().numpy())\n",
    "\n",
    "train_images = np.concatenate(train_images)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    data = Variable(data).to('cuda')\n",
    "    input = data.view(data.size(0), -1).to('cuda')\n",
    "    test_images.append(input.cpu().numpy())\n",
    "    test_labels.append(target.cpu().numpy())\n",
    "\n",
    "test_images = np.concatenate(test_images)\n",
    "test_labels = np.concatenate(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classification\n",
    "Objective: find the hyperplane that best separates the classes in the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9183\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(max_iter=1000, C=1.0)\n",
    "svc.fit(train_images, train_labels)\n",
    "\n",
    "predictions = svc.predict(test_images)\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SAE and DAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [44928/60000 (100%)]\tLoss: 0.000213: 100%|██████████| 469/469 [00:02<00:00, 165.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 0.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Documents/UNI_LOCAL/developing-autoencoders/solver.py:308: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data = Variable(data, volatile=True).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0196\n",
      "Directory created: /home/david/sparsify_models/AE/MNIST/2024-11-08_10-05-23/Static/\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [44928/60000 (100%)]\tLoss: 0.000184: 100%|██████████| 469/469 [00:02<00:00, 188.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 0.0183\n",
      "====> Test set loss: 0.0170\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44928/60000 (100%)]\tLoss: 0.000186: 100%|██████████| 469/469 [00:02<00:00, 198.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 2 Average loss: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44928/60000 (100%)]\tLoss: 0.000179: 100%|██████████| 469/469 [00:02<00:00, 221.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 3 Average loss: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [44928/60000 (100%)]\tLoss: 0.000193: 100%|██████████| 469/469 [00:01<00:00, 244.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 4 Average loss: 0.0174\n",
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [44928/60000 (100%)]\tLoss: 0.000190: 100%|██████████| 469/469 [00:01<00:00, 242.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 5 Average loss: 0.0173\n",
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [44928/60000 (100%)]\tLoss: 0.000164: 100%|██████████| 469/469 [00:02<00:00, 199.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 6 Average loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [44928/60000 (100%)]\tLoss: 0.000188: 100%|██████████| 469/469 [00:02<00:00, 230.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 7 Average loss: 0.0173\n",
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [44928/60000 (100%)]\tLoss: 0.000183: 100%|██████████| 469/469 [00:01<00:00, 267.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 8 Average loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [44928/60000 (100%)]\tLoss: 0.000176: 100%|██████████| 469/469 [00:01<00:00, 241.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 9 Average loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n",
      "All train losses saved.\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(n_input=784, n_hidden_ls=[512, 128, 32], n_layers=3)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5, momentum=0.99)\n",
    "\n",
    "train_losses, vali_losses = train_vali_all_epochs(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    optimizer, \n",
    "    n_epochs=10, \n",
    "    device=torch.device('cuda'), \n",
    "    save_path=save_path+'Static/'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: /home/david/sparsify_models/AE/MNIST/2024-11-08_10-05-23/Dev/cell_division/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [44928/60000 (100%)]\tLoss: 0.001272: 100%|██████████| 469/469 [00:03<00:00, 118.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 0.1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.1278\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Documents/UNI_LOCAL/developing-autoencoders/solver.py:184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(save_path + 'model_weights_epoch{}.pth'.format(epoch-1))\n",
      "Train Epoch: 1 [44928/60000 (100%)]\tLoss: 0.000514: 100%|██████████| 469/469 [00:05<00:00, 90.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 0.0610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0492\n",
      "Weights saved.\n",
      "debug var_dim 0\n",
      "debug var_dim 0\n",
      "debug var_dim 1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44928/60000 (100%)]\tLoss: 0.000531: 100%|██████████| 469/469 [00:05<00:00, 83.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 2 Average loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0482\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44928/60000 (100%)]\tLoss: 0.000456: 100%|██████████| 469/469 [00:05<00:00, 89.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 3 Average loss: 0.0474\n",
      "====> Test set loss: 0.0447\n",
      "Weights saved.\n",
      "debug var_dim 0\n",
      "debug var_dim 0\n",
      "debug var_dim 1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [44928/60000 (100%)]\tLoss: 0.000436: 100%|██████████| 469/469 [00:07<00:00, 62.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 4 Average loss: 0.0442\n",
      "====> Test set loss: 0.0427\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [44928/60000 (100%)]\tLoss: 0.000390: 100%|██████████| 469/469 [00:05<00:00, 78.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 5 Average loss: 0.0410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0380\n",
      "Weights saved.\n",
      "debug var_dim 0\n",
      "debug var_dim 0\n",
      "debug var_dim 1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [44928/60000 (100%)]\tLoss: 0.000359: 100%|██████████| 469/469 [00:04<00:00, 95.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 6 Average loss: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0345\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [44928/60000 (100%)]\tLoss: 0.000335: 100%|██████████| 469/469 [00:05<00:00, 87.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 7 Average loss: 0.0338\n",
      "====> Test set loss: 0.0325\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [44928/60000 (100%)]\tLoss: 0.000333: 100%|██████████| 469/469 [00:04<00:00, 102.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 8 Average loss: 0.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0316\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [44928/60000 (100%)]\tLoss: 0.000327: 100%|██████████| 469/469 [00:04<00:00, 108.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 9 Average loss: 0.0319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0314\n",
      "Weights saved.\n",
      "All train losses saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.12551082500707367,\n",
       "  0.0610077448093942,\n",
       "  0.04914438274146905,\n",
       "  0.0473549341453291,\n",
       "  0.0441921301710326,\n",
       "  0.04103026133197457,\n",
       "  0.03725110040481157,\n",
       "  0.03384170191152009,\n",
       "  0.03240955732603953,\n",
       "  0.03191359384831335],\n",
       " [0.12776172953315929,\n",
       "  0.04921401546725744,\n",
       "  0.04818867264857775,\n",
       "  0.04472514878534063,\n",
       "  0.04267358610147162,\n",
       "  0.03798164031173609,\n",
       "  0.03450405762731275,\n",
       "  0.032526041628627836,\n",
       "  0.031643614031468766,\n",
       "  0.03138792793018908])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_model = Autoencoder(n_input=784, n_hidden_ls=[512, 128, 32], n_layers=3)\n",
    "dev_optimizer = torch.optim.SGD(dev_model.parameters(), lr=0.5, momentum=0.99)\n",
    "\n",
    "size_ls = [4,10,16,32]\n",
    "manner = 'cell_division'\n",
    "\n",
    "dev_train_vali_all_epochs(\n",
    "    dev_model,\n",
    "    size_ls,\n",
    "    manner,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    optimizer,\n",
    "    n_epochs=10,\n",
    "    device='cpu',\n",
    "    save_path=save_path+'Dev/{}/'.format(manner)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying reconstructions of SAE and DAE with Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = Variable(data).to('cuda')\n",
    "        input = data.view(data.size(0), -1).to('cuda')\n",
    "        encoded, decoded = model(input)\n",
    "        reconstructions.append(decoded.cpu().numpy())\n",
    "\n",
    "reconstructions = np.concatenate(reconstructions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE Test Accuracy: 0.8780\n"
     ]
    }
   ],
   "source": [
    "ae_predictions = svc.predict(reconstructions)\n",
    "accuracy = accuracy_score(ae_predictions, test_labels)\n",
    "print(f'AE Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_reconstructions = []\n",
    "dev_model.eval()\n",
    "\n",
    "# Loop through validation data\n",
    "with torch.no_grad():  # Gradients not calculated\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = Variable(data).to('cpu')\n",
    "        input = data.view(data.size(0), -1).to('cpu')\n",
    "        encoded, decoded = dev_model(input)\n",
    "        dev_reconstructions.append(decoded.cpu().numpy())\n",
    "\n",
    "dev_reconstructions = np.concatenate(dev_reconstructions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAE Test Accuracy: 0.0892\n"
     ]
    }
   ],
   "source": [
    "dae_predictions = svc.predict(dev_reconstructions)\n",
    "accuracy = accuracy_score(dae_predictions, test_labels)\n",
    "print(f'DAE Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise_skimage(images, var):\n",
    "    noisy_images = []\n",
    "    for image in images:\n",
    "        noisy_image = random_noise(image, mode='gaussian', var=var)\n",
    "        noisy_images.append(noisy_image)\n",
    "    \n",
    "    return noisy_images\n",
    "\n",
    "noisy_test_images = add_gaussian_noise_skimage(test_images, var=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_images[0].reshape(28, 28))\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(noisy_test_images[0].reshape(28, 28))\n",
    "plt.title('Noisy Image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying noisy reconstructions of SAE and DAE with Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_reconstructions = []\n",
    "model.eval()\n",
    "\n",
    "for image in noisy_test_images:\n",
    "    image = torch.tensor(image).float().to('cuda')\n",
    "    input = image.view(1, -1).to('cuda')\n",
    "    encoded, decoded = model(input)\n",
    "    noisy_reconstructions.append(decoded.cpu().detach().numpy())\n",
    "\n",
    "noisy_reconstructions = np.concatenate(noisy_reconstructions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_dev_reconstructions = []\n",
    "dev_model.eval()\n",
    "\n",
    "for image in noisy_test_images:\n",
    "    image = torch.tensor(image).float().to('cpu')\n",
    "    input = image.view(1, -1).to('cpu')\n",
    "    encoded, decoded = dev_model(input)\n",
    "    noisy_dev_reconstructions.append(decoded.cpu().detach().numpy())\n",
    "\n",
    "noisy_dev_reconstructions = np.concatenate(noisy_dev_reconstructions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE Test Accuracy: 0.7259\n",
      "DAE Test Accuracy: 0.0892\n"
     ]
    }
   ],
   "source": [
    "noisy_ae_predictions = svc.predict(noisy_reconstructions)\n",
    "accuracy = accuracy_score(noisy_ae_predictions, test_labels)\n",
    "print(f'AE Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "noisy_dae_predictions = svc.predict(noisy_dev_reconstructions)\n",
    "accuracy = accuracy_score(noisy_dae_predictions, test_labels)\n",
    "print(f'DAE Test Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
