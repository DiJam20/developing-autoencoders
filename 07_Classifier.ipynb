{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import random_noise\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from autoencoder import Autoencoder\n",
    "from solver import train_vali_all_epochs, dev_train_vali_all_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/david/sparsify_models/AE/MNIST/2024-11-07_22-11-40/\n"
     ]
    }
   ],
   "source": [
    "run_id = datetime.today().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "save_path = os.getenv(\"HOME\") + '/sparsify_models/AE/MNIST/' +run_id +'/'\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9184\n"
     ]
    }
   ],
   "source": [
    "# Convert MNIST data to numpy arrays\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data = Variable(data).to('cuda')\n",
    "    input = data.view(data.size(0), -1).to('cuda')\n",
    "    train_images.append(input.cpu().numpy())\n",
    "    train_labels.append(target.cpu().numpy())\n",
    "\n",
    "train_images = np.concatenate(train_images)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    data = Variable(data).to('cuda')\n",
    "    input = data.view(data.size(0), -1).to('cuda')\n",
    "    test_images.append(input.cpu().numpy())\n",
    "    test_labels.append(target.cpu().numpy())\n",
    "\n",
    "test_images = np.concatenate(test_images)\n",
    "test_labels = np.concatenate(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classification\n",
    "Objective: find the hyperplane that best separates the classes in the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC(max_iter=1000, C=1.0)\n",
    "svc.fit(train_images, train_labels)\n",
    "\n",
    "predictions = svc.predict(test_images)\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SAE and DAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [44928/60000 (100%)]\tLoss: 0.000204: 100%|██████████| 469/469 [00:03<00:00, 150.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 0.0348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Documents/UNI_LOCAL/developing-autoencoders/solver.py:308: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data = Variable(data, volatile=True).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0194\n",
      "Directory created: /home/david/sparsify_models/AE/MNIST/2024-11-07_22-11-40/Static/\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [44928/60000 (100%)]\tLoss: 0.000185: 100%|██████████| 469/469 [00:02<00:00, 165.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0170\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44928/60000 (100%)]\tLoss: 0.000184: 100%|██████████| 469/469 [00:02<00:00, 159.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 2 Average loss: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44928/60000 (100%)]\tLoss: 0.000176: 100%|██████████| 469/469 [00:02<00:00, 160.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 3 Average loss: 0.0174\n",
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [44928/60000 (100%)]\tLoss: 0.000193: 100%|██████████| 469/469 [00:02<00:00, 161.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 4 Average loss: 0.0173\n",
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [44928/60000 (100%)]\tLoss: 0.000179: 100%|██████████| 469/469 [00:02<00:00, 162.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 5 Average loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [44928/60000 (100%)]\tLoss: 0.000185: 100%|██████████| 469/469 [00:02<00:00, 166.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 6 Average loss: 0.0173\n",
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [44928/60000 (100%)]\tLoss: 0.000190: 100%|██████████| 469/469 [00:02<00:00, 166.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 7 Average loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [44928/60000 (100%)]\tLoss: 0.000186: 100%|██████████| 469/469 [00:02<00:00, 163.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 8 Average loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [44928/60000 (100%)]\tLoss: 0.000187: 100%|██████████| 469/469 [00:02<00:00, 160.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 9 Average loss: 0.0173\n",
      "====> Test set loss: 0.0168\n",
      "Weights saved.\n",
      "All train losses saved.\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(n_input=784, n_hidden_ls=[512, 128, 32], n_layers=3)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5, momentum=0.99)\n",
    "\n",
    "train_losses, vali_losses = train_vali_all_epochs(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    optimizer, \n",
    "    n_epochs=10, \n",
    "    device=torch.device('cuda'), \n",
    "    save_path=save_path+'Static/'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: /home/david/sparsify_models/AE/MNIST/2024-11-07_22-11-40/Dev/cell_division/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [44928/60000 (100%)]\tLoss: 0.001301: 100%|██████████| 469/469 [00:05<00:00, 87.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 0.1244\n",
      "====> Test set loss: 0.1267\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Documents/UNI_LOCAL/developing-autoencoders/solver.py:184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(save_path + 'model_weights_epoch{}.pth'.format(epoch-1))\n",
      "Train Epoch: 1 [44928/60000 (100%)]\tLoss: 0.000531: 100%|██████████| 469/469 [00:05<00:00, 80.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 0.0604\n",
      "====> Test set loss: 0.0503\n",
      "Weights saved.\n",
      "debug var_dim 0\n",
      "debug var_dim 0\n",
      "debug var_dim 1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44928/60000 (100%)]\tLoss: 0.000518: 100%|██████████| 469/469 [00:05<00:00, 87.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 2 Average loss: 0.0492\n",
      "====> Test set loss: 0.0482\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44928/60000 (100%)]\tLoss: 0.000468: 100%|██████████| 469/469 [00:05<00:00, 83.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 3 Average loss: 0.0477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0455\n",
      "Weights saved.\n",
      "debug var_dim 0\n",
      "debug var_dim 0\n",
      "debug var_dim 1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [44928/60000 (100%)]\tLoss: 0.000420: 100%|██████████| 469/469 [00:05<00:00, 83.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 4 Average loss: 0.0436\n",
      "====> Test set loss: 0.0418\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [44928/60000 (100%)]\tLoss: 0.000382: 100%|██████████| 469/469 [00:05<00:00, 84.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 5 Average loss: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0385\n",
      "Weights saved.\n",
      "debug var_dim 0\n",
      "debug var_dim 0\n",
      "debug var_dim 1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [44928/60000 (100%)]\tLoss: 0.000369: 100%|██████████| 469/469 [00:06<00:00, 77.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 6 Average loss: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0347\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [44928/60000 (100%)]\tLoss: 0.000351: 100%|██████████| 469/469 [00:05<00:00, 79.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 7 Average loss: 0.0340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0326\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [44928/60000 (100%)]\tLoss: 0.000338: 100%|██████████| 469/469 [00:05<00:00, 83.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 8 Average loss: 0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0318\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [44928/60000 (100%)]\tLoss: 0.000360: 100%|██████████| 469/469 [00:05<00:00, 82.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 9 Average loss: 0.0322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0316\n",
      "Weights saved.\n",
      "All train losses saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.12437311118281981,\n",
       "  0.06041320302148363,\n",
       "  0.04923544333242912,\n",
       "  0.047725777564717256,\n",
       "  0.04356101841560559,\n",
       "  0.04105662185150677,\n",
       "  0.03716627708566723,\n",
       "  0.03399702063056706,\n",
       "  0.03262384694967189,\n",
       "  0.032181185259144186],\n",
       " [0.1267468529411509,\n",
       "  0.050273904553319836,\n",
       "  0.048202261894564086,\n",
       "  0.04551675632784638,\n",
       "  0.041836506250915645,\n",
       "  0.03848310710885857,\n",
       "  0.03473927257464656,\n",
       "  0.032631034927466246,\n",
       "  0.031790543677686134,\n",
       "  0.03157543579611597])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_model = Autoencoder(n_input=784, n_hidden_ls=[512, 128, 32], n_layers=3)\n",
    "dev_optimizer = torch.optim.SGD(dev_model.parameters(), lr=0.5, momentum=0.99)\n",
    "\n",
    "size_ls = [4,10,16,32]\n",
    "manner = 'cell_division'\n",
    "\n",
    "dev_train_vali_all_epochs(\n",
    "    dev_model,\n",
    "    size_ls,\n",
    "    manner,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    optimizer,\n",
    "    n_epochs=10,\n",
    "    device='cpu',\n",
    "    save_path=save_path+'Dev/{}/'.format(manner)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying reconstructions of SAE and DAE with Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = Variable(data).to('cuda')\n",
    "        input = data.view(data.size(0), -1).to('cuda')\n",
    "        encoded, decoded = model(input)\n",
    "        reconstructions.append(decoded.cpu().numpy())\n",
    "\n",
    "reconstructions = np.concatenate(reconstructions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE Test Accuracy: 0.8775\n"
     ]
    }
   ],
   "source": [
    "ae_predictions = svc.predict(reconstructions)\n",
    "accuracy = accuracy_score(ae_predictions, test_labels)\n",
    "print(f'AE Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_reconstructions = []\n",
    "dev_model.eval()\n",
    "\n",
    "# Loop through validation data\n",
    "with torch.no_grad():  # Gradients not calculated\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = Variable(data).to('cpu')\n",
    "        input = data.view(data.size(0), -1).to('cpu')\n",
    "        encoded, decoded = dev_model(input)\n",
    "        dev_reconstructions.append(decoded.cpu().numpy())\n",
    "\n",
    "dev_reconstructions = np.concatenate(dev_reconstructions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAE Test Accuracy: 0.0892\n"
     ]
    }
   ],
   "source": [
    "dae_predictions = svc.predict(dev_reconstructions)\n",
    "accuracy = accuracy_score(dae_predictions, test_labels)\n",
    "print(f'DAE Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise_skimage(images, var):\n",
    "    noisy_images = []\n",
    "    for image in images:\n",
    "        noisy_image = random_noise(image, mode='gaussian', var=var)\n",
    "        noisy_images.append(noisy_image)\n",
    "    \n",
    "    return noisy_images\n",
    "\n",
    "noisy_test_images = add_gaussian_noise_skimage(test_images, var=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_images[0].reshape(28, 28))\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(noisy_test_images[0].reshape(28, 28))\n",
    "plt.title('Noisy Image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying noisy reconstructions of SAE and DAE with Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_reconstructions = []\n",
    "model.eval()\n",
    "\n",
    "for image in noisy_test_images:\n",
    "    image = torch.tensor(image).float().to('cuda')\n",
    "    input = image.view(1, -1).to('cuda')\n",
    "    encoded, decoded = model(input)\n",
    "    noisy_reconstructions.append(decoded.cpu().detach().numpy())\n",
    "\n",
    "noisy_reconstructions = np.concatenate(noisy_reconstructions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_dev_reconstructions = []\n",
    "dev_model.eval()\n",
    "\n",
    "for image in noisy_test_images:\n",
    "    image = torch.tensor(image).float().to('cpu')\n",
    "    input = image.view(1, -1).to('cpu')\n",
    "    encoded, decoded = dev_model(input)\n",
    "    noisy_dev_reconstructions.append(decoded.cpu().detach().numpy())\n",
    "\n",
    "noisy_dev_reconstructions = np.concatenate(noisy_dev_reconstructions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE Test Accuracy: 0.4039\n",
      "DAE Test Accuracy: 0.0895\n"
     ]
    }
   ],
   "source": [
    "noisy_ae_predictions = svc.predict(noisy_reconstructions)\n",
    "accuracy = accuracy_score(noisy_ae_predictions, test_labels)\n",
    "print(f'AE Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "noisy_dae_predictions = svc.predict(noisy_dev_reconstructions)\n",
    "accuracy = accuracy_score(noisy_dae_predictions, test_labels)\n",
    "print(f'DAE Test Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
