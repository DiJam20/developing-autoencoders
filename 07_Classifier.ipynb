{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import random_noise\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from autoencoder import Autoencoder\n",
    "from solver import train_vali_all_epochs, dev_train_vali_all_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/david/sparsify_models/AE/MNIST/2024-11-13_21-23-02/\n"
     ]
    }
   ],
   "source": [
    "run_id = datetime.today().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "save_path = os.getenv(\"HOME\") + '/sparsify_models/AE/MNIST/' +run_id +'/'\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MNIST data to numpy arrays\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data = Variable(data).to('cuda')\n",
    "    input = data.view(data.size(0), -1).to('cuda')\n",
    "    train_images.append(input.cpu().numpy())\n",
    "    train_labels.append(target.cpu().numpy())\n",
    "\n",
    "train_images = np.concatenate(train_images)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    data = Variable(data).to('cuda')\n",
    "    input = data.view(data.size(0), -1).to('cuda')\n",
    "    test_images.append(input.cpu().numpy())\n",
    "    test_labels.append(target.cpu().numpy())\n",
    "\n",
    "test_images = np.concatenate(test_images)\n",
    "test_labels = np.concatenate(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SAE and DAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [44928/60000 (100%)]\tLoss: 0.000212: 100%|██████████| 469/469 [00:01<00:00, 263.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 0.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Documents/UNI_LOCAL/developing-autoencoders/solver.py:308: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data = Variable(data, volatile=True).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0194\n",
      "Directory created: /home/david/sparsify_models/AE/MNIST/2024-11-13_21-23-02/Static/\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [44928/60000 (100%)]\tLoss: 0.000184: 100%|██████████| 469/469 [00:01<00:00, 271.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0170\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44928/60000 (100%)]\tLoss: 0.000177: 100%|██████████| 469/469 [00:01<00:00, 271.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 2 Average loss: 0.0174\n",
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44928/60000 (100%)]\tLoss: 0.000182: 100%|██████████| 469/469 [00:01<00:00, 281.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 3 Average loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [44928/60000 (100%)]\tLoss: 0.000183: 100%|██████████| 469/469 [00:01<00:00, 274.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 4 Average loss: 0.0173\n",
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [44928/60000 (100%)]\tLoss: 0.000176: 100%|██████████| 469/469 [00:01<00:00, 245.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 5 Average loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [44928/60000 (100%)]\tLoss: 0.000188: 100%|██████████| 469/469 [00:01<00:00, 257.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 6 Average loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [44928/60000 (100%)]\tLoss: 0.000170: 100%|██████████| 469/469 [00:01<00:00, 262.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 7 Average loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [44928/60000 (100%)]\tLoss: 0.000169: 100%|██████████| 469/469 [00:01<00:00, 252.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 8 Average loss: 0.0173\n",
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [44928/60000 (100%)]\tLoss: 0.000173: 100%|██████████| 469/469 [00:01<00:00, 252.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 9 Average loss: 0.0173\n",
      "====> Test set loss: 0.0169\n",
      "Weights saved.\n",
      "All train losses saved.\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(n_input=784, n_hidden_ls=[512, 128, 32], n_layers=3)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5, momentum=0.99)\n",
    "\n",
    "train_losses, vali_losses = train_vali_all_epochs(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    optimizer, \n",
    "    n_epochs=10, \n",
    "    device=torch.device('cuda'), \n",
    "    save_path=save_path+'Static/'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: /home/david/sparsify_models/AE/MNIST/2024-11-13_21-23-02/Dev/cell_division/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [44928/60000 (100%)]\tLoss: 0.001219: 100%|██████████| 469/469 [00:03<00:00, 125.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 0.1240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.1264\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Documents/UNI_LOCAL/developing-autoencoders/solver.py:184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(save_path + 'model_weights_epoch{}.pth'.format(epoch-1))\n",
      "Train Epoch: 1 [44928/60000 (100%)]\tLoss: 0.000534: 100%|██████████| 469/469 [00:04<00:00, 111.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 0.0614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0497\n",
      "Weights saved.\n",
      "debug var_dim 0\n",
      "debug var_dim 0\n",
      "debug var_dim 1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44928/60000 (100%)]\tLoss: 0.000528: 100%|██████████| 469/469 [00:04<00:00, 110.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 2 Average loss: 0.0493\n",
      "====> Test set loss: 0.0481\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44928/60000 (100%)]\tLoss: 0.000468: 100%|██████████| 469/469 [00:04<00:00, 106.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 3 Average loss: 0.0472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0445\n",
      "Weights saved.\n",
      "debug var_dim 0\n",
      "debug var_dim 0\n",
      "debug var_dim 1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [44928/60000 (100%)]\tLoss: 0.000451: 100%|██████████| 469/469 [00:03<00:00, 119.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 4 Average loss: 0.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0422\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [44928/60000 (100%)]\tLoss: 0.000395: 100%|██████████| 469/469 [00:03<00:00, 120.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 5 Average loss: 0.0410\n",
      "====> Test set loss: 0.0386\n",
      "Weights saved.\n",
      "debug var_dim 0\n",
      "debug var_dim 0\n",
      "debug var_dim 1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [44928/60000 (100%)]\tLoss: 0.000367: 100%|██████████| 469/469 [00:03<00:00, 122.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 6 Average loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0341\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [44928/60000 (100%)]\tLoss: 0.000343: 100%|██████████| 469/469 [00:03<00:00, 121.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 7 Average loss: 0.0336\n",
      "====> Test set loss: 0.0323\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [44928/60000 (100%)]\tLoss: 0.000321: 100%|██████████| 469/469 [00:03<00:00, 119.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 8 Average loss: 0.0324\n",
      "====> Test set loss: 0.0317\n",
      "Weights saved.\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug var_dim -1\n",
      "debug nan in encoder weights tensor(0)\n",
      "debug nan in encoder bias tensor(0)\n",
      "debug nan in decoder weights tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [44928/60000 (100%)]\tLoss: 0.000346: 100%|██████████| 469/469 [00:03<00:00, 124.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 9 Average loss: 0.0321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0316\n",
      "Weights saved.\n",
      "All train losses saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.12401275730717665,\n",
       "  0.06136203836848233,\n",
       "  0.049313220928218576,\n",
       "  0.04717493681574681,\n",
       "  0.04362518732735851,\n",
       "  0.041038263080788576,\n",
       "  0.03691972967689988,\n",
       "  0.0335889178187227,\n",
       "  0.03243857010928934,\n",
       "  0.03212244793582064],\n",
       " [0.12637330327607407,\n",
       "  0.049714682364388356,\n",
       "  0.04807254643757132,\n",
       "  0.0445371747865707,\n",
       "  0.042203810584696036,\n",
       "  0.03855222331572183,\n",
       "  0.034065472598694545,\n",
       "  0.03226721119371396,\n",
       "  0.03172949380889724,\n",
       "  0.0315772064407415])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_model = Autoencoder(n_input=784, n_hidden_ls=[512, 128, 32], n_layers=3)\n",
    "dev_optimizer = torch.optim.SGD(dev_model.parameters(), lr=0.5, momentum=0.99)\n",
    "\n",
    "size_ls = [4,10,16,32]\n",
    "manner = 'cell_division'\n",
    "\n",
    "dev_train_vali_all_epochs(\n",
    "    dev_model,\n",
    "    size_ls,\n",
    "    manner,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    optimizer,\n",
    "    n_epochs=10,\n",
    "    device='cpu',\n",
    "    save_path=save_path+'Dev/{}/'.format(manner)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = []\n",
    "train_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = Variable(data).to('cuda')\n",
    "        input = data.view(data.size(0), -1).to('cuda')\n",
    "        encoded, decoded = model(input)\n",
    "        train_encodings.append(encoded.cpu().detach().numpy())\n",
    "        train_labels.append(target.cpu().numpy())\n",
    "\n",
    "train_encodings = np.concatenate(train_encodings)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "\n",
    "test_encodings = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = Variable(data).to('cuda')\n",
    "        input = data.view(data.size(0), -1).to('cuda')\n",
    "        encoded, decoded = model(input)\n",
    "        test_encodings.append(encoded.cpu().detach().numpy())\n",
    "        test_labels.append(target.cpu().numpy())\n",
    "\n",
    "test_encodings = np.concatenate(test_encodings)\n",
    "test_labels = np.concatenate(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_train_encodings = []\n",
    "dev_train_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = Variable(data).to('cuda')\n",
    "        input = data.view(data.size(0), -1).to('cpu')\n",
    "        encoded, decoded = dev_model(input)\n",
    "        dev_train_encodings.append(encoded.cpu().detach().numpy())\n",
    "        dev_train_labels.append(target.cpu().numpy())\n",
    "\n",
    "dev_train_encodings = np.concatenate(dev_train_encodings)\n",
    "dev_train_labels = np.concatenate(dev_train_labels)\n",
    "\n",
    "dev_test_encodings = []\n",
    "dev_test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = Variable(data).to('cuda')\n",
    "        input = data.view(data.size(0), -1).to('cpu')\n",
    "        encoded, decoded = dev_model(input)\n",
    "        dev_test_encodings.append(encoded.cpu().detach().numpy())\n",
    "        dev_test_labels.append(target.cpu().numpy())\n",
    "\n",
    "dev_test_encodings = np.concatenate(dev_test_encodings)\n",
    "dev_test_labels = np.concatenate(dev_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying encodings of SAE and DAE with a Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8865\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(max_iter=1000, C=1.0)\n",
    "svc.fit(train_encodings, train_labels)\n",
    "\n",
    "predictions = svc.predict(test_encodings)\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7377\n"
     ]
    }
   ],
   "source": [
    "dev_svc = LinearSVC(max_iter=1000, C=1.0)\n",
    "dev_svc.fit(dev_train_encodings, dev_train_labels)\n",
    "\n",
    "predictions = dev_svc.predict(dev_test_encodings)\n",
    "accuracy = accuracy_score(dev_test_labels, predictions)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(raw_data, var):\n",
    "    noisy_data = []\n",
    "    for original in raw_data:\n",
    "        noisy = random_noise(original, mode='gaussian', var=var)\n",
    "        noisy_data.append(noisy)\n",
    "    \n",
    "    return noisy_data\n",
    "\n",
    "def add_poisson_noise(raw_data):\n",
    "    noisy_data = []\n",
    "    for original in raw_data:\n",
    "        noisy = random_noise(original, mode='poisson')\n",
    "        noisy_data.append(noisy)\n",
    "    \n",
    "    return noisy_data\n",
    "\n",
    "def add_sp_noise(raw_data, amount):\n",
    "    noisy_data = []\n",
    "    for original in raw_data:\n",
    "        noisy = random_noise(original, mode='s&p', amount=amount)\n",
    "        noisy_data.append(noisy)\n",
    "    \n",
    "    return noisy_data\n",
    "\n",
    "\n",
    "noisy_test_images = add_sp_noise(test_images, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_images[0].reshape(28, 28))\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(noisy_test_images[0].reshape(28, 28))\n",
    "plt.title('Noisy Image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying noisy reconstructions of SAE and DAE with Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_test_encodings = []\n",
    "model.eval()\n",
    "\n",
    "for image in noisy_test_images:\n",
    "    image = torch.tensor(image).float().to('cuda')\n",
    "    input = image.view(1, -1).to('cuda')\n",
    "    encoded, decoded = model(input)\n",
    "    noisy_test_encodings.append(encoded.cpu().detach().numpy())\n",
    "\n",
    "noisy_test_encodings = np.concatenate(noisy_test_encodings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_dev_test_encodings = []\n",
    "dev_model.eval()\n",
    "\n",
    "for image in noisy_test_images:\n",
    "    image = torch.tensor(image).float().to('cpu')\n",
    "    input = image.view(1, -1).to('cpu')\n",
    "    encoded, decoded = dev_model(input)\n",
    "    noisy_dev_test_encodings.append(encoded.cpu().detach().numpy())\n",
    "\n",
    "noisy_dev_test_encodings = np.concatenate(noisy_dev_test_encodings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE Test Accuracy: 0.8066\n",
      "DAE Test Accuracy: 0.3566\n"
     ]
    }
   ],
   "source": [
    "noisy_ae_predictions = svc.predict(noisy_test_encodings)\n",
    "accuracy = accuracy_score(noisy_ae_predictions, test_labels)\n",
    "print(f'AE Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "noisy_dae_predictions = dev_svc.predict(noisy_dev_test_encodings)\n",
    "accuracy = accuracy_score(noisy_dae_predictions, test_labels)\n",
    "print(f'DAE Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_train_encodings = []\n",
    "dev_model.eval()\n",
    "\n",
    "for image in add_gaussian_noise(train_images, 0.1):\n",
    "    image = torch.tensor(image).float().to('cpu')\n",
    "    input = image.view(1, -1).to('cpu')\n",
    "    encoded, decoded = dev_model(input)\n",
    "    noisy_train_encodings.append(encoded.cpu().detach().numpy())\n",
    "\n",
    "noisy_train_encodings = np.concatenate(noisy_train_encodings, axis=0)\n",
    "\n",
    "noisy_dev_train_encodings = []\n",
    "dev_model.eval()\n",
    "\n",
    "for image in add_gaussian_noise(train_images, 0.1):\n",
    "    image = torch.tensor(image).float().to('cpu')\n",
    "    input = image.view(1, -1).to('cpu')\n",
    "    encoded, decoded = dev_model(input)\n",
    "    noisy_dev_train_encodings.append(encoded.cpu().detach().numpy())\n",
    "\n",
    "noisy_dev_train_encodings = np.concatenate(noisy_dev_train_encodings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy AE Test Accuracy: 0.0593\n",
      "Noisy DAE Test Accuracy: 0.1130\n"
     ]
    }
   ],
   "source": [
    "# Testing a SVC trained on noisy DAE encodings\n",
    "noisy_svc = LinearSVC(max_iter=1000, C=1.0)\n",
    "noisy_svc.fit(noisy_train_encodings, train_labels)\n",
    "\n",
    "predictions = noisy_svc.predict(noisy_test_encodings)\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "print(f'Noisy AE Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "noisy_dev_svc = LinearSVC(max_iter=1000, C=1.0)\n",
    "noisy_dev_svc.fit(noisy_dev_train_encodings, train_labels)\n",
    "\n",
    "predictions = noisy_dev_svc.predict(noisy_dev_test_encodings)\n",
    "dev_accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "print(f'Noisy DAE Test Accuracy: {dev_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for var in [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    noisy_test_images = add_gaussian_noise(test_images, var)\n",
    "    noisy_test_encodings = []\n",
    "    model.eval()\n",
    "\n",
    "    for image in noisy_test_images:\n",
    "        image = torch.tensor(image).float().to('cuda')\n",
    "        input = image.view(1, -1).to('cuda')\n",
    "        encoded, decoded = model(input)\n",
    "        noisy_test_encodings.append(encoded.cpu().detach().numpy())\n",
    "\n",
    "    noisy_test_encodings = np.concatenate(noisy_test_encodings, axis=0)\n",
    "\n",
    "    noisy_ae_predictions = svc.predict(noisy_test_encodings)\n",
    "    accuracy = accuracy_score(noisy_ae_predictions, test_labels)\n",
    "    data.append((var, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options to evaluate\n",
    "- Noisy images -> encode -> classify\n",
    "    - SVC trained on original images (data too large)\n",
    "    - SVC trained on noisy images (data too large)\n",
    "- Noisy encodings -> classify\n",
    "    - SVC trained on original encodings (SAE = 0.82, DAE = 0.39)\n",
    "    - SVC trained on noisy encodings (SAE = 0.06, DAE = 0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_images_train\n",
    "# noisy_images_test\n",
    "# noisy_image_encodings_train\n",
    "# noisy_image_encodings_test\n",
    "\n",
    "# train_images\n",
    "# test_images\n",
    "# noisy_encodings_test\n",
    "# noisy_encodings_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "noisy_images_train = add_gaussian_noise(train_images, 0.1)\n",
    "noisy_images_test = add_gaussian_noise(test_images, 0.1)\n",
    "\n",
    "noisy_image_encodings_train = []\n",
    "model.eval()\n",
    "for image in noisy_images_train:\n",
    "    image = torch.tensor(image).float().to('cuda')\n",
    "    input = image.view(1, -1).to('cuda')\n",
    "    encoded, decoded = model(input)\n",
    "    noisy_image_encodings_train.append(encoded.cpu().detach().numpy())\n",
    "noisy_image_encodings_train = np.concatenate(noisy_image_encodings_train, axis=0)\n",
    "\n",
    "noisy_image_encodings_test = []\n",
    "model.eval()\n",
    "for image in noisy_images_test:\n",
    "    image = torch.tensor(image).float().to('cuda')\n",
    "    input = image.view(1, -1).to('cuda')\n",
    "    encoded, decoded = model(input)\n",
    "    noisy_image_encodings_test.append(encoded.cpu().detach().numpy())\n",
    "noisy_image_encodings_test = np.concatenate(noisy_image_encodings_test, axis=0)\n",
    "\n",
    "train_images = train_images\n",
    "test_images = test_images\n",
    "\n",
    "noisy_encodings_train = []\n",
    "for image in train_images:\n",
    "    image = torch.tensor(image).float().to('cuda')\n",
    "    input = image.view(1, -1).to('cuda')\n",
    "    encoded, decoded = model(input)\n",
    "    noisy_encodings_train.append(encoded.cpu().detach().numpy())\n",
    "noisy_encodings_train = np.concatenate(noisy_encodings_train, axis=0)\n",
    "\n",
    "noisy_encodings_test = []\n",
    "for image in test_images:\n",
    "    image = torch.tensor(image).float().to('cuda')\n",
    "    input = image.view(1, -1).to('cuda')\n",
    "    encoded, decoded = model(input)\n",
    "    noisy_encodings_test.append(encoded.cpu().detach().numpy())\n",
    "noisy_encodings_test = np.concatenate(noisy_encodings_test, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svc = LinearSVC(max_iter=1000, C=1.0)\n",
    "svc.fit(train_images, train_labels)\n",
    "predictions = svc.predict(test_images)\n",
    "accuracy1 = accuracy_score(predictions, test_labels)\n",
    "print(accuracy1)\n",
    "\n",
    "dev_svc = LinearSVC(max_iter=1000, C=1.0)\n",
    "dev_svc.fit(train_images, train_labels)\n",
    "predictions = dev_svc.predict(test_images)\n",
    "accuracy2 = accuracy_score(predictions, test_labels)\n",
    "print(accuracy2)\n",
    "\n",
    "predictions = svc.predict(noisy_images_test)\n",
    "accuracy3 = accuracy_score(predictions, test_labels)\n",
    "print(accuracy3)\n",
    "\n",
    "predictions = dev_svc.predict(noisy_images_test)\n",
    "accuracy4 = accuracy_score(predictions, test_labels)\n",
    "print(accuracy4)\n",
    "\n",
    "noisy_svc = LinearSVC(max_iter=1000, C=1.0)\n",
    "noisy_svc.fit(noisy_images_train, train_labels)\n",
    "predictions = noisy_svc.predict(noisy_images_test)\n",
    "accuracy5 = accuracy_score(test_labels, predictions)\n",
    "print(accuracy5)\n",
    "\n",
    "noisy_dev_svc = LinearSVC(max_iter=1000, C=1.0)\n",
    "noisy_dev_svc.fit(noisy_images_train, train_labels)\n",
    "predictions = noisy_dev_svc.predict(noisy_images_test)\n",
    "accuracy6 = accuracy_score(test_labels, predictions)\n",
    "print(accuracy6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_noise_impact(data):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.plot([d['noiseVar'] for d in data], [d['gaussianAccuracy'] for d in data], label='Gaussian Noise')\n",
    "    plt.plot([d['noiseVar'] for d in data], [d['poissonAccuracy'] for d in data], label='Poisson Noise')\n",
    "    plt.plot([d['noiseVar'] for d in data], [d['saltPepperAccuracy'] for d in data], label='Salt & Pepper Noise')\n",
    "    \n",
    "    plt.xlabel('Noise Variance')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Impact of Noise on Autoencoder Encoding Classification')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "data = [\n",
    "    {'noiseVar': 0.01, 'gaussianAccuracy': 0.92, 'poissonAccuracy': 0.89, 'saltPepperAccuracy': 0.85},\n",
    "    {'noiseVar': 0.05, 'gaussianAccuracy': 0.87, 'poissonAccuracy': 0.84, 'saltPepperAccuracy': 0.78},\n",
    "    {'noiseVar': 0.1, 'gaussianAccuracy': 0.81, 'poissonAccuracy': 0.79, 'saltPepperAccuracy': 0.71},\n",
    "    {'noiseVar': 0.15, 'gaussianAccuracy': 0.75, 'poissonAccuracy': 0.72, 'saltPepperAccuracy': 0.65},\n",
    "    {'noiseVar': 0.2, 'gaussianAccuracy': 0.68, 'poissonAccuracy': 0.65, 'saltPepperAccuracy': 0.58},\n",
    "]\n",
    "\n",
    "plot_noise_impact(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
